{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "056b6eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix, roc_curve, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree     import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "e3e96b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Final_cleaned_file_for_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "0b05004a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>001</th>\n",
       "      <th>0010</th>\n",
       "      <th>007</th>\n",
       "      <th>01</th>\n",
       "      <th>01022017</th>\n",
       "      <th>01242017</th>\n",
       "      <th>0130</th>\n",
       "      <th>0150</th>\n",
       "      <th>018</th>\n",
       "      <th>...</th>\n",
       "      <th>z132</th>\n",
       "      <th>z332</th>\n",
       "      <th>zaf</th>\n",
       "      <th>zamac</th>\n",
       "      <th>zero</th>\n",
       "      <th>zinc</th>\n",
       "      <th>zinco</th>\n",
       "      <th>zn</th>\n",
       "      <th>zone</th>\n",
       "      <th>Accident_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>1540</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>1541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>1542</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>1543</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>1544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1545 rows × 3338 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  001  0010  007  01  01022017  01242017  0130  0150  018  \\\n",
       "0              0    0     0    0   0         0         0     0     0    0   \n",
       "1              1    0     0    0   0         0         0     0     0    0   \n",
       "2              2    0     0    0   0         0         0     0     0    0   \n",
       "3              3    0     0    0   0         0         0     0     0    0   \n",
       "4              4    0     0    0   0         0         0     0     0    0   \n",
       "...          ...  ...   ...  ...  ..       ...       ...   ...   ...  ...   \n",
       "1540        1540    0     0    0   0         0         0     0     0    0   \n",
       "1541        1541    0     0    0   0         0         0     0     0    0   \n",
       "1542        1542    0     0    0   0         0         0     0     0    0   \n",
       "1543        1543    0     0    0   0         0         0     0     0    0   \n",
       "1544        1544    0     0    0   0         0         0     0     0    0   \n",
       "\n",
       "      ...  z132  z332  zaf  zamac  zero  zinc  zinco  zn  zone  Accident_Level  \n",
       "0     ...     0     0    0      0     0     0      0   0     0               1  \n",
       "1     ...     0     0    0      0     0     0      0   0     0               1  \n",
       "2     ...     0     0    0      0     0     0      0   0     0               1  \n",
       "3     ...     0     0    0      0     0     0      0   0     0               1  \n",
       "4     ...     0     0    1      0     0     0      0   0     0               4  \n",
       "...   ...   ...   ...  ...    ...   ...   ...    ...  ..   ...             ...  \n",
       "1540  ...     0     0    0      0     0     0      0   0     0               5  \n",
       "1541  ...     0     0    0      0     0     0      0   0     0               5  \n",
       "1542  ...     0     0    0      0     0     0      0   0     0               5  \n",
       "1543  ...     0     0    0      0     0     0      0   0     0               5  \n",
       "1544  ...     0     0    0      0     0     0      0   0     0               5  \n",
       "\n",
       "[1545 rows x 3338 columns]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "03ca5156",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "ae77a7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>001</th>\n",
       "      <th>0010</th>\n",
       "      <th>007</th>\n",
       "      <th>01</th>\n",
       "      <th>01022017</th>\n",
       "      <th>01242017</th>\n",
       "      <th>0130</th>\n",
       "      <th>0150</th>\n",
       "      <th>018</th>\n",
       "      <th>0183</th>\n",
       "      <th>...</th>\n",
       "      <th>z132</th>\n",
       "      <th>z332</th>\n",
       "      <th>zaf</th>\n",
       "      <th>zamac</th>\n",
       "      <th>zero</th>\n",
       "      <th>zinc</th>\n",
       "      <th>zinco</th>\n",
       "      <th>zn</th>\n",
       "      <th>zone</th>\n",
       "      <th>Accident_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1545 rows × 3337 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      001  0010  007  01  01022017  01242017  0130  0150  018  0183  ...  \\\n",
       "0       0     0    0   0         0         0     0     0    0     0  ...   \n",
       "1       0     0    0   0         0         0     0     0    0     0  ...   \n",
       "2       0     0    0   0         0         0     0     0    0     0  ...   \n",
       "3       0     0    0   0         0         0     0     0    0     0  ...   \n",
       "4       0     0    0   0         0         0     0     0    0     0  ...   \n",
       "...   ...   ...  ...  ..       ...       ...   ...   ...  ...   ...  ...   \n",
       "1540    0     0    0   0         0         0     0     0    0     0  ...   \n",
       "1541    0     0    0   0         0         0     0     0    0     0  ...   \n",
       "1542    0     0    0   0         0         0     0     0    0     0  ...   \n",
       "1543    0     0    0   0         0         0     0     0    0     0  ...   \n",
       "1544    0     0    0   0         0         0     0     0    0     0  ...   \n",
       "\n",
       "      z132  z332  zaf  zamac  zero  zinc  zinco  zn  zone  Accident_Level  \n",
       "0        0     0    0      0     0     0      0   0     0               1  \n",
       "1        0     0    0      0     0     0      0   0     0               1  \n",
       "2        0     0    0      0     0     0      0   0     0               1  \n",
       "3        0     0    0      0     0     0      0   0     0               1  \n",
       "4        0     0    1      0     0     0      0   0     0               4  \n",
       "...    ...   ...  ...    ...   ...   ...    ...  ..   ...             ...  \n",
       "1540     0     0    0      0     0     0      0   0     0               5  \n",
       "1541     0     0    0      0     0     0      0   0     0               5  \n",
       "1542     0     0    0      0     0     0      0   0     0               5  \n",
       "1543     0     0    0      0     0     0      0   0     0               5  \n",
       "1544     0     0    0      0     0     0      0   0     0               5  \n",
       "\n",
       "[1545 rows x 3337 columns]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa2b6a6",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "4abc9c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Accident_Level'],axis = 1)\n",
    "y = data['Accident_Level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "ef0a2ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = data['Accident_Level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "a2b7d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "7326046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver = 'lbfgs')\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr1 = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "84a23ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9592969472710453"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "180730dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.834051724137931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.71      0.77        87\n",
      "           2       0.81      0.75      0.78       103\n",
      "           3       0.84      0.82      0.83        87\n",
      "           4       0.71      0.89      0.79        90\n",
      "           5       1.00      1.00      1.00        97\n",
      "\n",
      "    accuracy                           0.83       464\n",
      "   macro avg       0.84      0.83      0.83       464\n",
      "weighted avg       0.84      0.83      0.83       464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy %s' % accuracy_score(y_pred_lr1, y_test))\n",
    "print(classification_report(y_test, y_pred_lr1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "ab10785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver = 'liblinear')\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr2 = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "a46ebd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9481961147086031"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "b6db2a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8448275862068966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.72      0.78        87\n",
      "           2       0.82      0.82      0.82       103\n",
      "           3       0.82      0.80      0.81        87\n",
      "           4       0.76      0.87      0.81        90\n",
      "           5       0.99      1.00      0.99        97\n",
      "\n",
      "    accuracy                           0.84       464\n",
      "   macro avg       0.85      0.84      0.84       464\n",
      "weighted avg       0.85      0.84      0.84       464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy %s' % accuracy_score(y_pred_lr2, y_test))\n",
    "print(classification_report(y_test, y_pred_lr2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca341f1",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "de5b23e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "a714ef83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8381128584643849"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "1601b939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7155172413793104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.03      0.07        87\n",
      "           2       0.58      0.72      0.64       103\n",
      "           3       0.75      0.83      0.79        87\n",
      "           4       0.61      0.96      0.74        90\n",
      "           5       1.00      1.00      1.00        97\n",
      "\n",
      "    accuracy                           0.72       464\n",
      "   macro avg       0.79      0.71      0.65       464\n",
      "weighted avg       0.78      0.72      0.66       464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred_knn))\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "6c5bc4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_nb = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "d20fb639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8011100832562442"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "386ddcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7155172413793104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.03      0.07        87\n",
      "           2       0.58      0.72      0.64       103\n",
      "           3       0.75      0.83      0.79        87\n",
      "           4       0.61      0.96      0.74        90\n",
      "           5       1.00      1.00      1.00        97\n",
      "\n",
      "    accuracy                           0.72       464\n",
      "   macro avg       0.79      0.71      0.65       464\n",
      "weighted avg       0.78      0.72      0.66       464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b981b0a",
   "metadata": {},
   "source": [
    "### Using SVM is not good option/ not preferred for multi class classification, but just checking its results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "d6dc48a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In its most basic type, SVM doesn't support multiclass classification. For multiclass classification, the same principle is \n",
    "#utilized after breaking down the multi-classification problem into smaller subproblems, all of which are binary \n",
    "#classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "9fb44ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(gamma=0.1, C=3)\n",
    "\n",
    "svm.fit(X_train , y_train)\n",
    "\n",
    "y_pred_svm = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "f9268067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9574468085106383"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "9ed1e12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8405172413793104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.99      0.82        87\n",
      "           2       0.91      0.68      0.78       103\n",
      "           3       0.92      0.76      0.83        87\n",
      "           4       0.75      0.81      0.78        90\n",
      "           5       1.00      0.98      0.99        97\n",
      "\n",
      "    accuracy                           0.84       464\n",
      "   macro avg       0.86      0.84      0.84       464\n",
      "weighted avg       0.86      0.84      0.84       464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "7a4c2689",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1, 1, 3, 5, 10],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "0d8d202e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END ....................C=0.1, gamma=1;, score=0.244 total time=   2.1s\n",
      "[CV 2/5] END ....................C=0.1, gamma=1;, score=0.356 total time=   1.7s\n",
      "[CV 3/5] END ....................C=0.1, gamma=1;, score=0.375 total time=   1.9s\n",
      "[CV 4/5] END ....................C=0.1, gamma=1;, score=0.324 total time=   1.9s\n",
      "[CV 5/5] END ....................C=0.1, gamma=1;, score=0.287 total time=   1.7s\n",
      "[CV 1/5] END ..................C=0.1, gamma=0.1;, score=0.622 total time=   1.4s\n",
      "[CV 2/5] END ..................C=0.1, gamma=0.1;, score=0.676 total time=   1.5s\n",
      "[CV 3/5] END ..................C=0.1, gamma=0.1;, score=0.630 total time=   1.5s\n",
      "[CV 4/5] END ..................C=0.1, gamma=0.1;, score=0.644 total time=   1.8s\n",
      "[CV 5/5] END ..................C=0.1, gamma=0.1;, score=0.694 total time=   1.5s\n",
      "[CV 1/5] END .................C=0.1, gamma=0.01;, score=0.318 total time=   1.7s\n",
      "[CV 2/5] END .................C=0.1, gamma=0.01;, score=0.296 total time=   2.2s\n",
      "[CV 3/5] END .................C=0.1, gamma=0.01;, score=0.324 total time=   1.7s\n",
      "[CV 4/5] END .................C=0.1, gamma=0.01;, score=0.319 total time=   1.7s\n",
      "[CV 5/5] END .................C=0.1, gamma=0.01;, score=0.301 total time=   1.8s\n",
      "[CV 1/5] END ................C=0.1, gamma=0.001;, score=0.203 total time=   1.9s\n",
      "[CV 2/5] END ................C=0.1, gamma=0.001;, score=0.204 total time=   1.8s\n",
      "[CV 3/5] END ................C=0.1, gamma=0.001;, score=0.204 total time=   1.8s\n",
      "[CV 4/5] END ................C=0.1, gamma=0.001;, score=0.241 total time=   1.7s\n",
      "[CV 5/5] END ................C=0.1, gamma=0.001;, score=0.204 total time=   1.7s\n",
      "[CV 1/5] END ...............C=0.1, gamma=0.0001;, score=0.203 total time=   2.3s\n",
      "[CV 2/5] END ...............C=0.1, gamma=0.0001;, score=0.204 total time=   1.9s\n",
      "[CV 3/5] END ...............C=0.1, gamma=0.0001;, score=0.204 total time=   2.0s\n",
      "[CV 4/5] END ...............C=0.1, gamma=0.0001;, score=0.231 total time=   1.8s\n",
      "[CV 5/5] END ...............C=0.1, gamma=0.0001;, score=0.204 total time=   1.8s\n",
      "[CV 1/5] END ......................C=1, gamma=1;, score=0.710 total time=   1.8s\n",
      "[CV 2/5] END ......................C=1, gamma=1;, score=0.741 total time=   1.4s\n",
      "[CV 3/5] END ......................C=1, gamma=1;, score=0.699 total time=   1.4s\n",
      "[CV 4/5] END ......................C=1, gamma=1;, score=0.722 total time=   1.4s\n",
      "[CV 5/5] END ......................C=1, gamma=1;, score=0.741 total time=   1.5s\n",
      "[CV 1/5] END ....................C=1, gamma=0.1;, score=0.774 total time=   1.1s\n",
      "[CV 2/5] END ....................C=1, gamma=0.1;, score=0.852 total time=   1.2s\n",
      "[CV 3/5] END ....................C=1, gamma=0.1;, score=0.815 total time=   1.2s\n",
      "[CV 4/5] END ....................C=1, gamma=0.1;, score=0.866 total time=   1.3s\n",
      "[CV 5/5] END ....................C=1, gamma=0.1;, score=0.866 total time=   1.2s\n",
      "[CV 1/5] END ...................C=1, gamma=0.01;, score=0.733 total time=   1.3s\n",
      "[CV 2/5] END ...................C=1, gamma=0.01;, score=0.741 total time=   1.3s\n",
      "[CV 3/5] END ...................C=1, gamma=0.01;, score=0.750 total time=   1.2s\n",
      "[CV 4/5] END ...................C=1, gamma=0.01;, score=0.755 total time=   1.5s\n",
      "[CV 5/5] END ...................C=1, gamma=0.01;, score=0.796 total time=   1.3s\n",
      "[CV 1/5] END ..................C=1, gamma=0.001;, score=0.300 total time=   3.2s\n",
      "[CV 2/5] END ..................C=1, gamma=0.001;, score=0.250 total time=   3.6s\n",
      "[CV 3/5] END ..................C=1, gamma=0.001;, score=0.264 total time=   2.9s\n",
      "[CV 4/5] END ..................C=1, gamma=0.001;, score=0.259 total time=   3.2s\n",
      "[CV 5/5] END ..................C=1, gamma=0.001;, score=0.264 total time=   3.0s\n",
      "[CV 1/5] END .................C=1, gamma=0.0001;, score=0.203 total time=   2.8s\n",
      "[CV 2/5] END .................C=1, gamma=0.0001;, score=0.204 total time=   2.9s\n",
      "[CV 3/5] END .................C=1, gamma=0.0001;, score=0.204 total time=   2.8s\n",
      "[CV 4/5] END .................C=1, gamma=0.0001;, score=0.231 total time=   2.8s\n",
      "[CV 5/5] END .................C=1, gamma=0.0001;, score=0.204 total time=   2.9s\n",
      "[CV 1/5] END ......................C=3, gamma=1;, score=0.724 total time=   2.5s\n",
      "[CV 2/5] END ......................C=3, gamma=1;, score=0.764 total time=   2.4s\n",
      "[CV 3/5] END ......................C=3, gamma=1;, score=0.713 total time=   2.1s\n",
      "[CV 4/5] END ......................C=3, gamma=1;, score=0.736 total time=   2.1s\n",
      "[CV 5/5] END ......................C=3, gamma=1;, score=0.778 total time=   2.0s\n",
      "[CV 1/5] END ....................C=3, gamma=0.1;, score=0.783 total time=   1.7s\n",
      "[CV 2/5] END ....................C=3, gamma=0.1;, score=0.866 total time=   1.8s\n",
      "[CV 3/5] END ....................C=3, gamma=0.1;, score=0.838 total time=   1.7s\n",
      "[CV 4/5] END ....................C=3, gamma=0.1;, score=0.861 total time=   1.8s\n",
      "[CV 5/5] END ....................C=3, gamma=0.1;, score=0.884 total time=   1.8s\n",
      "[CV 1/5] END ...................C=3, gamma=0.01;, score=0.770 total time=   1.6s\n",
      "[CV 2/5] END ...................C=3, gamma=0.01;, score=0.824 total time=   1.7s\n",
      "[CV 3/5] END ...................C=3, gamma=0.01;, score=0.792 total time=   1.9s\n",
      "[CV 4/5] END ...................C=3, gamma=0.01;, score=0.833 total time=   1.6s\n",
      "[CV 5/5] END ...................C=3, gamma=0.01;, score=0.815 total time=   1.7s\n",
      "[CV 1/5] END ..................C=3, gamma=0.001;, score=0.590 total time=   2.6s\n",
      "[CV 2/5] END ..................C=3, gamma=0.001;, score=0.560 total time=   2.7s\n",
      "[CV 3/5] END ..................C=3, gamma=0.001;, score=0.514 total time=   2.5s\n",
      "[CV 4/5] END ..................C=3, gamma=0.001;, score=0.574 total time=   2.6s\n",
      "[CV 5/5] END ..................C=3, gamma=0.001;, score=0.583 total time=   2.7s\n",
      "[CV 1/5] END .................C=3, gamma=0.0001;, score=0.203 total time=   2.9s\n",
      "[CV 2/5] END .................C=3, gamma=0.0001;, score=0.204 total time=   2.8s\n",
      "[CV 3/5] END .................C=3, gamma=0.0001;, score=0.204 total time=   2.6s\n",
      "[CV 4/5] END .................C=3, gamma=0.0001;, score=0.231 total time=   2.9s\n",
      "[CV 5/5] END .................C=3, gamma=0.0001;, score=0.204 total time=   2.7s\n",
      "[CV 1/5] END ......................C=5, gamma=1;, score=0.724 total time=   2.2s\n",
      "[CV 2/5] END ......................C=5, gamma=1;, score=0.764 total time=   2.3s\n",
      "[CV 3/5] END ......................C=5, gamma=1;, score=0.713 total time=   2.4s\n",
      "[CV 4/5] END ......................C=5, gamma=1;, score=0.736 total time=   2.6s\n",
      "[CV 5/5] END ......................C=5, gamma=1;, score=0.778 total time=   2.2s\n",
      "[CV 1/5] END ....................C=5, gamma=0.1;, score=0.797 total time=   2.0s\n",
      "[CV 2/5] END ....................C=5, gamma=0.1;, score=0.866 total time=   1.8s\n",
      "[CV 3/5] END ....................C=5, gamma=0.1;, score=0.843 total time=   1.9s\n",
      "[CV 4/5] END ....................C=5, gamma=0.1;, score=0.852 total time=   1.8s\n",
      "[CV 5/5] END ....................C=5, gamma=0.1;, score=0.880 total time=   2.0s\n",
      "[CV 1/5] END ...................C=5, gamma=0.01;, score=0.779 total time=   1.4s\n",
      "[CV 2/5] END ...................C=5, gamma=0.01;, score=0.829 total time=   1.4s\n",
      "[CV 3/5] END ...................C=5, gamma=0.01;, score=0.796 total time=   1.7s\n",
      "[CV 4/5] END ...................C=5, gamma=0.01;, score=0.833 total time=   1.6s\n",
      "[CV 5/5] END ...................C=5, gamma=0.01;, score=0.829 total time=   1.7s\n",
      "[CV 1/5] END ..................C=5, gamma=0.001;, score=0.659 total time=   2.5s\n",
      "[CV 2/5] END ..................C=5, gamma=0.001;, score=0.602 total time=   2.7s\n",
      "[CV 3/5] END ..................C=5, gamma=0.001;, score=0.653 total time=   2.7s\n",
      "[CV 4/5] END ..................C=5, gamma=0.001;, score=0.648 total time=   2.6s\n",
      "[CV 5/5] END ..................C=5, gamma=0.001;, score=0.685 total time=   2.5s\n",
      "[CV 1/5] END .................C=5, gamma=0.0001;, score=0.203 total time=   2.8s\n",
      "[CV 2/5] END .................C=5, gamma=0.0001;, score=0.204 total time=   3.0s\n",
      "[CV 3/5] END .................C=5, gamma=0.0001;, score=0.204 total time=   3.0s\n",
      "[CV 4/5] END .................C=5, gamma=0.0001;, score=0.231 total time=   2.8s\n",
      "[CV 5/5] END .................C=5, gamma=0.0001;, score=0.204 total time=   2.8s\n",
      "[CV 1/5] END .....................C=10, gamma=1;, score=0.724 total time=   2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .....................C=10, gamma=1;, score=0.764 total time=   2.5s\n",
      "[CV 3/5] END .....................C=10, gamma=1;, score=0.713 total time=   2.4s\n",
      "[CV 4/5] END .....................C=10, gamma=1;, score=0.736 total time=   2.3s\n",
      "[CV 5/5] END .....................C=10, gamma=1;, score=0.778 total time=   2.2s\n",
      "[CV 1/5] END ...................C=10, gamma=0.1;, score=0.797 total time=   1.9s\n",
      "[CV 2/5] END ...................C=10, gamma=0.1;, score=0.861 total time=   1.8s\n",
      "[CV 3/5] END ...................C=10, gamma=0.1;, score=0.852 total time=   1.8s\n",
      "[CV 4/5] END ...................C=10, gamma=0.1;, score=0.852 total time=   1.8s\n",
      "[CV 5/5] END ...................C=10, gamma=0.1;, score=0.889 total time=   1.7s\n",
      "[CV 1/5] END ..................C=10, gamma=0.01;, score=0.788 total time=   1.2s\n",
      "[CV 2/5] END ..................C=10, gamma=0.01;, score=0.843 total time=   1.2s\n",
      "[CV 3/5] END ..................C=10, gamma=0.01;, score=0.806 total time=   1.3s\n",
      "[CV 4/5] END ..................C=10, gamma=0.01;, score=0.833 total time=   1.4s\n",
      "[CV 5/5] END ..................C=10, gamma=0.01;, score=0.847 total time=   1.3s\n",
      "[CV 1/5] END .................C=10, gamma=0.001;, score=0.742 total time=   2.2s\n",
      "[CV 2/5] END .................C=10, gamma=0.001;, score=0.718 total time=   2.0s\n",
      "[CV 3/5] END .................C=10, gamma=0.001;, score=0.750 total time=   2.2s\n",
      "[CV 4/5] END .................C=10, gamma=0.001;, score=0.731 total time=   2.2s\n",
      "[CV 5/5] END .................C=10, gamma=0.001;, score=0.778 total time=   2.2s\n",
      "[CV 1/5] END ................C=10, gamma=0.0001;, score=0.323 total time=   2.8s\n",
      "[CV 2/5] END ................C=10, gamma=0.0001;, score=0.245 total time=   2.8s\n",
      "[CV 3/5] END ................C=10, gamma=0.0001;, score=0.250 total time=   2.7s\n",
      "[CV 4/5] END ................C=10, gamma=0.0001;, score=0.250 total time=   2.8s\n",
      "[CV 5/5] END ................C=10, gamma=0.0001;, score=0.292 total time=   2.8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 3, 5, 10],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "e1592539",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "3f34b6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.1}\n",
      "SVC(C=10, gamma=0.1)\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    " \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "f16dc5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm_grid = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "34f06d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9703977798334875"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "b63db1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.834051724137931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.99      0.82        87\n",
      "           2       0.92      0.63      0.75       103\n",
      "           3       0.92      0.77      0.84        87\n",
      "           4       0.73      0.82      0.77        90\n",
      "           5       1.00      0.98      0.99        97\n",
      "\n",
      "    accuracy                           0.83       464\n",
      "   macro avg       0.85      0.84      0.83       464\n",
      "weighted avg       0.86      0.83      0.83       464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred_svm_grid))\n",
    "print(classification_report(y_test, y_pred_svm_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff591373",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "02cf10e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=1)"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(criterion='entropy', random_state = 1)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "3cf2a32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.973172987974098"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "8e12456a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7241379310344828"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576f7a60",
   "metadata": {},
   "source": [
    "* If we allow the tree to grow to max extent, there will always be overfitting in the model due to which the test accuracy drops drastically.\n",
    "* Hence, we'll Regularize/prune the decision tree by limiting the max. depth of trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b58ae3",
   "metadata": {},
   "source": [
    "### Regularized / Pruned Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "50fcac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_param = {'criterion':['gini','entropy'],'max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "53d3a7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_gs = GridSearchCV(DecisionTreeClassifier(), tree_param, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "ab9f4a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 20, 30,\n",
       "                                       40, 50, 70, 90, 120, 150]})"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "2a209412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 90}\n",
      "DecisionTreeClassifier(max_depth=90)\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning\n",
    "print(dt_gs.best_params_)\n",
    " \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(dt_gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "a36dd9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=90, random_state=1)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dt_pruned = DecisionTreeClassifier(criterion='entropy', max_depth = 100, random_state = 1)\n",
    "\n",
    "dt_pruned = DecisionTreeClassifier(criterion='gini', max_depth = 90, random_state = 1)\n",
    "dt_pruned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "ce87d78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dt_pruned = dt_pruned.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "ed44126b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.973172987974098"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_pruned.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "9fbd444f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7456896551724138\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.48      0.56        87\n",
      "           2       0.66      0.67      0.67       103\n",
      "           3       0.79      0.72      0.75        87\n",
      "           4       0.67      0.84      0.75        90\n",
      "           5       0.93      0.99      0.96        97\n",
      "\n",
      "    accuracy                           0.75       464\n",
      "   macro avg       0.74      0.74      0.74       464\n",
      "weighted avg       0.74      0.75      0.74       464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred_dt_pruned))\n",
    "print(classification_report(y_test, y_pred_dt_pruned))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c93bf3",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "391506cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()       #n_estimators = 50, max_depth =5, random_state=1)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "8ae6caf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.973172987974098"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "ac763a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8275862068965517\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.61      0.73        87\n",
      "           2       0.78      0.76      0.77       103\n",
      "           3       0.83      0.87      0.85        87\n",
      "           4       0.70      0.89      0.78        90\n",
      "           5       0.97      1.00      0.98        97\n",
      "\n",
      "    accuracy                           0.83       464\n",
      "   macro avg       0.84      0.83      0.82       464\n",
      "weighted avg       0.84      0.83      0.82       464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "30911f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "8fcf071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\"n_estimators\": [10,50,100,150,200],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(1, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=n_iter_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "0c11fb61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mridul.miglani\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mridul.miglani\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mridul.miglani\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\mridul.miglani\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\mridul.miglani\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\mridul.miglani\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\mridul.miglani\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\mridul.miglani\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\mridul.miglani\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mridul.miglani\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mridul.miglani\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\mridul.miglani\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\mridul.miglani\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\mridul.miglani\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mridul.miglani\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.24697047 0.2608935  0.40427121 0.80852961 0.494837          nan\n",
      " 0.26824117 0.33208739 0.29138505 0.32930961 0.60774876        nan\n",
      " 0.28592337 0.42095921        nan 0.43390937 0.4051502  0.28215566\n",
      " 0.50877283 0.25990783]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rf_rs = random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "525aeff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_features': 2, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "RandomForestClassifier(max_features=2, n_estimators=10)\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning\n",
    "print(rf_rs.best_params_)\n",
    " \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(rf_rs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "4e8fd733",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_rs = RandomForestClassifier(criterion= 'gini', max_features=6, min_samples_leaf=1, min_samples_split=6)\n",
    "\n",
    "rf_rs = rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf_rs = rf_rs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "ce0d8ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.973172987974098"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_rs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "a43a564d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8512931034482759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.78      0.80        87\n",
      "           2       0.83      0.76      0.79       103\n",
      "           3       0.90      0.83      0.86        87\n",
      "           4       0.74      0.89      0.81        90\n",
      "           5       0.97      1.00      0.98        97\n",
      "\n",
      "    accuracy                           0.85       464\n",
      "   macro avg       0.85      0.85      0.85       464\n",
      "weighted avg       0.85      0.85      0.85       464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred_rf_rs))\n",
    "print(classification_report(y_test, y_pred_rf_rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc5082d",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "79dc51b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:11:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier() #n_estimators = 100, learning_rate = 0.1, random_state=1)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "1b403016",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xgb = xgb.predict(X_test)\n",
    "acc_xgb  = accuracy_score(y_test, pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "09a37e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9685476410730804"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "0e31b888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8297413793103449"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f974b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7668a203",
   "metadata": {},
   "source": [
    "### Combine accuracy scores of models for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513cd419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877a6ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa63874b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
